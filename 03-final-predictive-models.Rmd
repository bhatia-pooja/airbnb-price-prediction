---
title: "MGT__256_Project_Predictive Models"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

Part 1: Repeating Data Cleaning Steps
```{r}
library(tidyverse)
```


```{r}
airbnb_palette <- c("#FF5A5F", "#00A699", "#767676", "#484848", "#FFB400")

main_uncleaned_data <- read_csv("airbnb1.csv")

# Calculate the percentage of missing data for each column
missing_data <- main_uncleaned_data %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Percentage")
```

```{r}
which(is.na(main_uncleaned_data))

col_missing <- colSums(is.na(main_uncleaned_data))

col_missing

dropped_na <- main_uncleaned_data %>% drop_na()

which(is.na(dropped_na)) # just checking if the cleaning worked or not

Q1 <- quantile(dropped_na$bedrooms, 0.25, na.rm = TRUE)
Q3 <- quantile(dropped_na$bedrooms, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1

cleaned_airbnb_data <- dropped_na %>%
  filter(bedrooms >= (Q1 - 1.5 * IQR) & bedrooms <= (Q3 + 1.5 * IQR))

glimpse(cleaned_airbnb_data)
```

```{r}
numeric_vars <- c("bathrooms", "bedrooms", "beds", "amenities_count", "minimum_nights", "maximum_nights", "number_of_reviews", "review_scores_rating", "price","availability_30","availability_60","availability_90","availability_365")

categorical_vars <- c("property_type", "room_type", "cancellation_policy", "instant_bookable")
```

New data cleaning step: Created dummy variables of all categorcal variables (room type, property type, host verification, cancelation)

```{r}
for (var in categorical_vars) {
  # Create dummy variables using model.matrix() and remove intercept column
  dummy_vars <- model.matrix(as.formula(paste("~", var, "- 1")), data = cleaned_airbnb_data)
  
  # Append dummy variables to the original dataset
  cleaned_airbnb_data <- cbind(cleaned_airbnb_data, dummy_vars)
}

# Drop columns by selecting the ones not in categorical_vars
cleaned_airbnb_data <- cleaned_airbnb_data[, !(names(cleaned_airbnb_data) %in% categorical_vars)]

# 
# # View the updated dataset to verify the dummy variables
glimpse(cleaned_airbnb_data)

```

Step 1: Splitting data into training and validation

```{r}
#splitting data
library(caret)
library(MASS)

set.seed(2)
trainIndex <- createDataPartition(cleaned_airbnb_data$price, p = 0.6, list = FALSE)
train <- cleaned_airbnb_data[trainIndex, ]
test <- cleaned_airbnb_data[-trainIndex, ]

colnames(train)[colnames(train) == "room_typeEntire home/apt"] <- "room_typeEntire_home/apt"
colnames(train)[colnames(train) == "property_typeBed & Breakfast"] <- "property_typeBed_&_Breakfast"

colnames(test)[colnames(test) == "room_typeEntire home/apt"] <- "room_typeEntire_home/apt"
colnames(test)[colnames(test) == "property_typeBed & Breakfast"] <- "property_typeBed_&_Breakfast"

```

Spet 2: Model Selection
Full model with all variables to find out significant and insignificant variables 
```{r}
#full model will all variables 

full_model <- lm(price ~ ., data = train)
summary(full_model)
```
Significant Variables (p < 0.05):

accommodates (2.48e-14 ***)
bathrooms (1.17e-12 ***)
bedrooms (0.003732 **)
amenities_count (< 2e-16 ***)
host_since (0.024177 *)
property_typeApartment (0.011291 *)
property_typeBed & Breakfast (0.000147 ***)
room_typeEntire home/apt (0.023806 *)

Model with only significant Vaiables
```{r}
# Check p-values from the model summary
summary(full_model)$coefficients

# Extract variable names with p-values < 0.05
significant_vars <- rownames(summary(full_model)$coefficients)[summary(full_model)$coefficients[, "Pr(>|t|)"] < 0.05]
print(significant_vars)

#making model 2 with only significant variables.

# Build the model using only the significant variables
linear_model_significant <- lm(price ~ accommodates + bathrooms + bedrooms + 
                               amenities_count + host_since + property_typeApartment +
                               `property_typeBed_&_Breakfast` + `room_typeEntire_home/apt`, 
                               data = train)

# Summarize the model to check the results
summary(linear_model_significant)

```

A model with only significal variables has a lower R^2 than the full model, hence this is not an effective model.

a) Random test model removing variables with high p-values till R^2 improves
```{r}
test_model <- lm(price ~ .-latitude-longitude-property_typeTownhouse-`room_typeEntire_home/apt`-cancellation_policystrict_14_with_grace_period-availability_30-availability_60-availability_90-availability_365-cancellation_policystrict-reviews_per_month-beds-property_typeCondominium-number_of_reviews-property_typeCastle-minimum_nights , data = train)
summary(test_model)
AIC(test_model)
```

b) Model using forward selection
```{r}
# Load the necessary library
library(MASS)

# Start with a null model (intercept only)
null_model <- lm(price ~ 1, data = train)

# Define the full model (including all potential predictors)
full_model <- lm(price ~ ., data = train)

# Perform forward selection using step()
forward_model <- step(null_model, scope = list(lower = null_model, upper = full_model), direction = "forward")

# Summarize the model obtained through forward selection
summary(forward_model)

# Calculate AIC for the forward-selected model
AIC(forward_model)

```

c) Model Using Backward Selection
```{r}
# Perform backward selection using step()
backward_model <- step(full_model, direction = "backward")

# Summarize the model obtained through backward selection
summary(backward_model)

# Calculate AIC for the backward-selected model
AIC(backward_model)

```

d) Model Using Exhaustive Search
```{r}
# Load required libraries
library(leaps)

# Perform exhaustive selection using regsubsets
exhaustive_model <- regsubsets(price ~ .,
                               data = train,
                               nbest = 1,           # Find the best model for each subset size
                               method = "exhaustive")

# Get a summary of the exhaustive search results
summary_exhaustive <- summary(exhaustive_model)

# Get the index of the model with the best Adjusted R-squared
best_adjr2 <- which.max(summary_exhaustive$adjr2)

# Extract the model with the best Adjusted R-squared
best_adjr2_model <- summary_exhaustive$which[best_adjr2, ]

# Get predictor names from the model with best Adjusted R-squared
selected_predictors <- names(best_adjr2_model)[best_adjr2_model][-1]  # Remove intercept

# Refit the model using the selected predictors
formula_str <- paste("price ~", paste(selected_predictors, collapse = " + "))
best_model_exhaustive <- lm(as.formula(formula_str), data = train)

# Calculate and print AIC for the best model based on Adjusted R-squared
best_model_aic_exhaustive <- AIC(best_model_exhaustive)
cat("AIC of the best model based on Adjusted R-squared:", best_model_aic_exhaustive, "\n")

summary(best_model_exhaustive)

```

Comparing r^2 and AIC of all models
```{r}
summary_forward <- summary(forward_model)             # Forward selection model
summary_backward <- summary(backward_model)           # Backward selection model
summary_test <- summary(test_model)                   # Original test model

# Extract Adjusted R-squared from each summary
adjusted_r2_forward <- summary_forward$adj.r.squared
adjusted_r2_backward <- summary_backward$adj.r.squared
adjusted_r2_test <- summary_test$adj.r.squared

# Print the Adjusted R-squared values for all models
cat("Adjusted R-squared of Forward Model:", adjusted_r2_forward, "\n")
cat("Adjusted R-squared of Backward Model:", adjusted_r2_backward, "\n")
cat("Adjusted R-squared of Exhaustive Best Model:", max(summary_exhaustive$adjr2), "\n")
cat("Adjusted R-squared of Original Best Model:", adjusted_r2_test, "\n")

# Extract and print AIC for each model
aic_forward <- AIC(forward_model)
aic_backward <- AIC(backward_model)
aic_test <- AIC(test_model)

cat("AIC of Forward Model:", aic_forward, "\n")
cat("AIC of Backward Model:", aic_backward, "\n")
cat("AIC of Exhaustive Best Model:", best_model_aic_exhaustive, "\n")
cat("AIC of Original Best Model:", aic_test, "\n")

```

Conclusion:FORWARD SELECTION GIVES BEST MODEL BASED ON Adjusted R^2 & AIC hence those will be the best variables:
amenities_count
accommodates
bedrooms
bathrooms
property_typeBed_&_Breakfast
room_typeEntire_home/apt
property_typeHouse
host_since
property_typeCondominium
property_typeTownhouse
maximum_nights
extra_people
cancellation_policystrict

```{r}
# Predict on the testing set using each model
predictions_forward <- predict(forward_model, newdata = test)
predictions_backward <- predict(backward_model, newdata = test)
predictions_test <- predict(test_model, newdata = test)
predictions_exhaustive <- predict(best_model_exhaustive, newdata = test)

# Load necessary package for accuracy metrics
library(Metrics)

# Calculate RMSE and R-squared for each model

# Forward Model
rmse_forward <- rmse(test$price, predictions_forward)
r2_forward <- cor(test$price, predictions_forward)^2

# Backward Model
rmse_backward <- rmse(test$price, predictions_backward)
r2_backward <- cor(test$price, predictions_backward)^2

# Original Test Model
rmse_test <- rmse(test$price, predictions_test)
r2_test <- cor(test$price, predictions_test)^2

# Exhaustive Best Model
rmse_exhaustive <- rmse(test$price, predictions_exhaustive)
r2_exhaustive <- cor(test$price, predictions_exhaustive)^2

# Print out RMSE and R-squared values for all models
cat("RMSE of Forward Model:", rmse_forward, "\n")
cat("R-squared of Forward Model:", r2_forward, "\n")

cat("RMSE of Backward Model:", rmse_backward, "\n")
cat("R-squared of Backward Model:", r2_backward, "\n")

cat("RMSE of Original Test Model:", rmse_test, "\n")
cat("R-squared of Original Test Model:", r2_test, "\n")

cat("RMSE of Exhaustive Best Model:", rmse_exhaustive, "\n")
cat("R-squared of Exhaustive Best Model:", r2_exhaustive, "\n")

```

Set-up cross validation controls
```{r}
# Set up cross-validation control
train_control <- trainControl(method = "cv", number = 10) # 10-fold cross-validation
```

e) Building a KNN Model
```{r}
# Run KNN with cross-validation
set.seed(2)
knn_model <- train(price ~ .,
                   data = train,
                   method = "knn",
                   trControl = train_control,
                   preProcess = c("center", "scale"), # Standardize the data
                   tuneLength = 10) # Tune the number of neighbors

# Summarize KNN model
print(knn_model)

# Make predictions on the test set
knn_predictions <- predict(knn_model, newdata = test)

# Evaluate performance on the test set
knn_rmse <- RMSE(knn_predictions, test$price)
cat("KNN RMSE:", knn_rmse, "\n")

```

```{r}
summary(knn_model)
```


```{r}
# Run KNN with cross-validation (selected variables)
set.seed(2)
knn_model_sv <- train(price ~ amenities_count + accommodates + bedrooms + 
                        bathrooms + `property_typeBed_&_Breakfast` + `room_typeEntire_home/apt` + 
                        property_typeHouse + host_since + property_typeCondominium + 
                        property_typeTownhouse + maximum_nights + extra_people + 
                        cancellation_policystrict ,
                   data = train,
                   method = "knn",
                   trControl = train_control,
                   preProcess = c("center", "scale"), # Standardize the data
                   tuneLength = 10) # Tune the number of neighbors

# Summarize KNN model
print(knn_model_sv)

# Make predictions on the test set
knn_predictions_sv <- predict(knn_model_sv, newdata = test)

# Evaluate performance on the test set
knn_rmse_sv <- RMSE(knn_predictions_sv, test$price)
cat("KNN RMSE (with selced variables:", knn_rmse_sv, "\n")

```

f) Liner regression on cross-validation with forward selection variables 
```{r}
# Run Linear Regression with cross-validation
set.seed(2)
lm_model <- train(price ~ amenities_count + accommodates + bedrooms + 
    bathrooms + `property_typeBed_&_Breakfast` + `room_typeEntire_home/apt` + 
    property_typeHouse + host_since + property_typeCondominium + 
    property_typeTownhouse + maximum_nights + extra_people + 
    cancellation_policystrict,
                  data = train,
                  method = "lm",
                  trControl = train_control)

# Summarize Linear Regression model
print(lm_model)

# Make predictions on the test set
lm_predictions <- predict(lm_model, newdata = test)

# Evaluate performance on the test set
lm_rmse <- RMSE(lm_predictions, test$price)
cat("Linear Regression RMSE:", lm_rmse, "\n")

```

```{r}
summary(lm_model) 

# Print out the RMSE values for comparison
cat("KNN RMSE:", knn_rmse, "\n")
cat("KNN RMSE(with selected variables):", knn_rmse_sv, "\n")
cat("Linear Regression RMSE:", lm_rmse, "\n")

```
The linear regression model with the variables identefied by forward selection is the best model.


```{r}
# Calculate residuals for each model
residuals_knn <- test$price - knn_predictions
residuals_knn_sv <- test$price - knn_predictions_sv
residuals_lm <- test$price - lm_predictions
```

```{r}
# Load required library
library(ggplot2)

# Residual vs. Fitted plot for LM Model
ggplot(data = NULL, aes(x = lm_predictions, y = residuals_lm)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "#00A699") +
  labs(title = "Residuals vs Fitted (LM Model)", x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```

```{r}
# Q-Q Plot for LM Model residuals
qqnorm(residuals_lm, main = "Q-Q Plot of Residuals (LM Model)")
qqline(residuals_lm, col = "#00A699")
```

```{r}
# Actual vs Predicted for LM Model
ggplot(data = NULL, aes(x = test$price, y = lm_predictions)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "#00A699") +
  labs(title = "Actual vs Predicted (LM Model)", x = "Actual Price", y = "Predicted Price") +
  theme_minimal()
```